<?xml version="1.0" encoding="UTF-8"?>
<jube>

	<parameterset name="parameter">
		<!-- TODO REMOVE WHEN FILE SUBSTITUTION WILL BE IMPLEMENTED -->
		<parameter	name="HACK_PATH">							../../../../../							</parameter>
		<!-- TODO END REMOVE WHEN FILE SUBSTITUTION WILL BE IMPLEMENTED -->
		<parameter	name="fileOutput">							../resource/ioFiles/defaultJube			</parameter>
		<parameter	name="filePathStatistic">					../resource/statistic/					</parameter>
		<parameter	name="CubeDumpResFile">						../resource/tmpCubeDumpFile				</parameter>
		<parameter	name="fileScriptPlot">						./srcPlot/mainPlot.py					</parameter>
		<parameter	name="fileScriptParseCubeDumpRes">			./srcPlot/mainParseCubeDumpResFile.py	</parameter>
		<parameter	name="nbIoDevice">							1										</parameter>
		<parameter	name="nbProcessor">							2										</parameter>
		<parameter	name="cube_save_id">						16										</parameter>
	</parameterset>


	<parameterset name="parameter_benchmarkResultFile">
		<parameter	name="fileExec"			type="str">			./posixGlibcAIO_sleep					</parameter>
		<parameter	name="computeTime"		type="float">		0										</parameter>
		<parameter name="benchmarkResultFile" type="str">
			${filePathStatistic}/${fileExec}_${computeTime}.data
		</parameter>
	</parameterset>

	<parameterset name="parameter_variableDim_nbIteration">
		<parameter	name="nbIteration"		type="int">			100, 1100, 2100, 3100, 4100, 5100, 6100, 7100, 8100, 9100, 10100, 11100, 12100, 13100, 14100, 15100, 16100, 17100, 18100, 19100, 20100, 21100, 22100, 23100, 24100, 25100, 26100, 27100, 28100, 29100, 30100, 31100, 32100, 33100, 34100, 35100, 36100, 37100, 38100, 39100, 40100, 41100, 42100, 43100, 44100, 45100, 46100, 47100, 48100, 49100, 50100, 51100, 52100, 53100, 54100, 55100, 56100, 57100, 58100, 59100, 60100, 61100, 62100, 63100, 64100, 65100, 66100, 67100, 68100, 69100, 70100, 71100, 72100, 73100, 74100, 75100, 76100, 77100, 78100, 79100, 80100, 81100, 82100, 83100, 84100, 85100, 86100, 87100, 88100, 89100, 90100, 91100, 92100, 93100, 94100, 95100, 96100, 97100, 98100, 99100 						</parameter>
	</parameterset>
	<parameterset name="parameter_variableDim_nbCharOutput">
		<parameter	name="nbCharOutput"		type="int">			 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000			</parameter>
	</parameterset>


	<!-- Operation -->
	<!-- Initializes all the results files: name = $HACK_PATH${filePathStatistic}/${fileExec}_${computeTime}.data -->
	<!-- Needs to be executed before any other operation -->
	<!-- Needs to be updated when we change the parameterset "parameter_benchmarkResultFile" -->
	<benchmark name="init_outputFile" outpath="bench_run">
		<comment>Creates and writes the header of the data files that will contain the benchmark pattern assessment results</comment>
		<step name="init_outputFile">
			<use>parameter						</use>
			<use>parameter_benchmarkResultFile	</use>
			<do>echo											>  $HACK_PATH${benchmarkResultFile}	</do>
 			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "#Benchmark pattern info:"					>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo ${fileExec}								>> $HACK_PATH${benchmarkResultFile}	</do>

 			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "#Fixed dim and values:"					>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "computeTime," ${computeTime}	 			>> $HACK_PATH${benchmarkResultFile}	</do>

			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "#Variable dim:"							>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "nbIteration,nbCharOutput"					>> $HACK_PATH${benchmarkResultFile}	</do>
<!-- TODO add the dimension (+ in the python mainPlot.py) -->
			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "#Result dim:"								>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
 			<do>echo "save time / nb Iteration"		>> $HACK_PATH${benchmarkResultFile}	</do>
 
 			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "#Data:"									>> $HACK_PATH${benchmarkResultFile}	</do>
			<do>echo "################################"			>> $HACK_PATH${benchmarkResultFile}	</do>
		</step>
	</benchmark>


	<!-- Operation -->
	<!-- Run the different pattern benchmarks and assess them -->
	<!-- Needs to be executed after "init_outputFile"-->
	<benchmark name="run_benchmark" outpath="bench_run">
		<comment>Run the different pattern benchmarks and assess them</comment>
		<step name="run_benchmark">
			<use>parameter</use>
			<use>parameter_benchmarkResultFile</use>
			<use>parameter_variableDim_nbIteration</use>
			<use>parameter_variableDim_nbCharOutput</use>
			<do>rm -rf  scorep-* </do>
			<!-- Execute the benchmark pattern and write the parameters (thanks to logger option m) -->
			<do>$HACK_PATH$fileExec	-nbIteration	$nbIteration			\
									-nbCharOutput	$nbCharOutput			\
									-computeTime	$computeTime			\
									-outputFile		$HACK_PATH$fileOutput	\
									-nbIoDevice		$nbIoDevice				\
									-nbProcessor	$nbProcessor			\
									-logger			m
			</do>
			<do> rm $HACK_PATH$fileOutput* </do>
			<do> echo ${nbIteration} ", " ${nbCharOutput} >> $HACK_PATH${benchmarkResultFile} </do>
			<do>cube_dump scorep-*/profile.cubex -m time -z incl -c ${cube_save_id}	> $HACK_PATH${CubeDumpResFile} </do>
 			<do> python $HACK_PATH${fileScriptParseCubeDumpRes} -divide=${nbIteration} $HACK_PATH${CubeDumpResFile} ${cube_save_id} >> $HACK_PATH${benchmarkResultFile} </do>
			<do> rm $HACK_PATH${CubeDumpResFile} </do>
			</step>
	</benchmark>



	<!-- Operation -->
	<!-- Run the different pattern benchmarks and assess them -->
	<!-- Needs to be executed after "init_outputFile"-->
	<benchmark name="run_benchmark_row" outpath="bench_run">
		<comment>Run the different pattern benchmarks and assess them</comment>
		<step name="run_benchmark_row">
			<use>parameter</use>
			<use>parameter_benchmarkResultFile</use>
			<use>parameter_variableDim_nbIteration</use>
			<use>parameter_variableDim_nbCharOutput</use>
			<do>rm -rf  scorep-* </do>
			<!-- Execute the benchmark pattern and write the parameters (thanks to logger option m) -->
			<do>$HACK_PATH$fileExec	-nbIteration	$nbIteration			\
									-nbCharOutput	$nbCharOutput			\
									-computeTime	$computeTime			\
									-outputFile		$HACK_PATH$fileOutput	\
									-nbIoDevice		$nbIoDevice				\
									-nbProcessor	$nbProcessor			\
									-logger			m
			</do>
			<do> rm $HACK_PATH$fileOutput* </do>
			<do> echo ${nbIteration} ", " ${nbCharOutput} >> $HACK_PATH${benchmarkResultFile} </do>
			<do>cube_dump scorep-*/profile.cubex -m time -z incl -c ${cube_save_id}	> $HACK_PATH${CubeDumpResFile} </do>
			<do> python $HACK_PATH${fileScriptParseCubeDumpRes} $HACK_PATH${CubeDumpResFile} ${cube_save_id} >> $HACK_PATH${benchmarkResultFile} </do>
			<do> rm $HACK_PATH${CubeDumpResFile} </do>
			</step>
	</benchmark>



	<!-- Operation -->
	<!-- Plot the results of all the benchmark pattern assessments -->
	<!-- Needs to be executed after "run_benchmark" -->
	<benchmark name="plotRequestTime" outpath="bench_run">
		<comment>Plot the results of all the benchmark pattern assessments</comment>
		<!-- Operation -->
		<step name="plotWriteTime">
			<use>parameter							</use>
			<use>parameter_benchmarkResultFile		</use>
			<use>parameter_variableDim_nbCharOutput	</use>
			<do> python $HACK_PATH${fileScriptPlot} $HACK_PATH${benchmarkResultFile} -plotType=point:nbCharOutput:${nbCharOutput}</do>
		</step>
	</benchmark>

</jube>
